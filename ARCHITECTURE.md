# AlloyMind AI - API Architecture Documentation

## ğŸ—ï¸ System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLIENT LAYER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Web Apps  â”‚  Mobile Apps  â”‚  Industrial Systems  â”‚  CLI Tools  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTP/REST API
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FASTAPI SERVER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   CORS      â”‚ â”‚ Request     â”‚ â”‚ Response    â”‚ â”‚   Error     â”‚ â”‚
â”‚ â”‚ Middleware  â”‚ â”‚ Validation  â”‚ â”‚ Formatting  â”‚ â”‚  Handling   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PREDICTION ENGINE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ Multi-Grade â”‚ â”‚ ASTMA536    â”‚ â”‚ ASTMA395    â”‚                 â”‚
â”‚ â”‚   Model     â”‚ â”‚ Updated     â”‚ â”‚ Updated     â”‚                 â”‚
â”‚ â”‚             â”‚ â”‚   Model     â”‚ â”‚   Model     â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ENSEMBLE ML MODELS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚        LIGHTGBM           â”‚ â”‚         CATBOOST              â”‚ â”‚
â”‚ â”‚                           â”‚ â”‚                               â”‚ â”‚
â”‚ â”‚ â€¢ GPU Accelerated         â”‚ â”‚ â€¢ Native Categorical          â”‚ â”‚
â”‚ â”‚ â€¢ StandardScaler          â”‚ â”‚ â€¢ No Preprocessing            â”‚ â”‚
â”‚ â”‚ â€¢ Weight: 50%             â”‚ â”‚ â€¢ Weight: 50%                 â”‚ â”‚
â”‚ â”‚                           â”‚ â”‚                               â”‚ â”‚
â”‚ â”‚ Elements:                 â”‚ â”‚ Elements:                     â”‚ â”‚
â”‚ â”‚ - C_Element_Config        â”‚ â”‚ - C_Element_Config            â”‚ â”‚
â”‚ â”‚ - Si_Element_Config       â”‚ â”‚ - Si_Element_Config           â”‚ â”‚
â”‚ â”‚ - Mn_Element_Config       â”‚ â”‚ - Mn_Element_Config           â”‚ â”‚
â”‚ â”‚ - P_Element_Config        â”‚ â”‚ - P_Element_Config            â”‚ â”‚
â”‚ â”‚ - S_Element_Config        â”‚ â”‚ - S_Element_Config            â”‚ â”‚
â”‚ â”‚ - Cu_Element_Config       â”‚ â”‚ - Cu_Element_Config           â”‚ â”‚
â”‚ â”‚ - Mg_Element_Config       â”‚ â”‚ - Mg_Element_Config           â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ FastAPI Implementation

### Core Application Structure

```python
# FastAPI Application Initialization
app = FastAPI(
    title="AlloyMind Element Configuration API",
    description="Advanced alloy optimization using ensemble ML models",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS Configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

### Request/Response Models (Pydantic)

```python
# Input Validation Schema
class CompositionInput(BaseModel):
    C: float = Field(..., ge=0, le=10, description="Carbon percentage (0-10%)")
    Si: float = Field(..., ge=0, le=10, description="Silicon percentage (0-10%)")
    Mn: float = Field(..., ge=0, le=2, description="Manganese percentage (0-2%)")
    P: float = Field(..., ge=0, le=1, description="Phosphorus percentage (0-1%)")
    S: float = Field(..., ge=0, le=0.1, description="Sulfur percentage (0-0.1%)")
    Cu: float = Field(..., ge=0, le=2, description="Copper percentage (0-2%)")
    Mg: float = Field(..., ge=0, le=0.2, description="Magnesium percentage (0-0.2%)")

# Prediction Request Schema
class PredictionRequest(BaseModel):
    alloy_grade: str = Field(..., description="Alloy grade")
    current_composition: CompositionInput
    furnace_id: Optional[str] = Field("F01", description="Furnace ID")

# Response Schema
class PredictionResponse(BaseModel):
    success: bool
    alloy_grade: str
    furnace_id: str
    target_specifications: Dict[str, float]
    element_predictions: List[ElementPrediction]
    optimization_insights: Dict[str, float]
    cost_analysis: CostAnalysis
    recommendations: List[str]
    model_performance: Dict[str, float]
```

## ğŸ¤– ML Model Architecture

### Ensemble Model Design

```python
class EnsembleModel:
    """Dual-ensemble approach combining LightGBM and CatBoost"""
    
    def __init__(self, lgbm_models, catboost_models, lgbm_scaler=None, weights=None):
        self.lgbm_models = lgbm_models        # Dict of LightGBM models per element
        self.catboost_models = catboost_models # Dict of CatBoost models per element
        self.lgbm_scaler = lgbm_scaler        # StandardScaler for LightGBM
        self.weights = weights or [0.5, 0.5]  # Ensemble weights [LightGBM, CatBoost]
    
    def predict(self, X):
        """Weighted ensemble prediction"""
        predictions = {}
        
        # Prepare scaled input for LightGBM
        X_scaled = self.lgbm_scaler.transform(X) if self.lgbm_scaler else X
        
        for element in self.target_elements:
            # Individual model predictions
            lgbm_pred = self.lgbm_models[element].predict(X_scaled)
            catboost_pred = self.catboost_models[element].predict(X)
            
            # Weighted ensemble
            ensemble_pred = (self.weights[0] * lgbm_pred + 
                           self.weights[1] * catboost_pred)
            predictions[element] = ensemble_pred
        
        return pd.DataFrame(predictions)
```

### Model Performance Metrics

| Component | Metric | Performance |
|-----------|--------|-------------|
| **LightGBM Models** | RÂ² Score | 99.99%+ |
| **CatBoost Models** | RÂ² Score | 99.99%+ |
| **Ensemble** | RMSE | <0.025 |
| **Inference Speed** | Latency | <50ms |
| **GPU Acceleration** | Training Speed | 5-10x faster |

### Model Loading Strategy

```python
# Global model storage
models = {}
model_info = {}

# Lazy loading of models
def load_model(model_name: str):
    """Load model only when needed (lazy loading)"""
    if model_name not in models:
        model_path = f"{model_name}_ensemble_model.pkl"
        models[model_name] = joblib.load(model_path)
        
        # Load training info
        info_path = f"{model_name}_training_info.json"
        with open(info_path, 'r') as f:
            model_info[model_name] = json.load(f)
    
    return models[model_name]
```

## ğŸ“Š Data Flow Architecture

### Prediction Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP Request    â”‚
â”‚ (JSON Payload)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pydantic        â”‚
â”‚ Validation      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature         â”‚
â”‚ Engineering     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Selection â”‚
â”‚ (Based on Grade)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ensemble        â”‚
â”‚ Prediction      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Post-processing â”‚
â”‚ & Optimization  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cost Analysis   â”‚
â”‚ & Insights      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JSON Response   â”‚
â”‚ (Structured)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Feature Engineering Pipeline

```python
def prepare_prediction_input(composition: dict, grade: str, furnace_id: str):
    """Transform raw input into model-ready features"""
    
    # Base features
    features = {
        'Alloy_Grade': grade,
        'Furnace_ID': furnace_id,
        **composition  # Element percentages
    }
    
    # Feature engineering
    features.update({
        'C_Si_Ratio': composition['C'] / max(composition['Si'], 0.01),
        'Mn_P_Ratio': composition['Mn'] / max(composition['P'], 0.001),
        'Total_Alloy_Content': sum([
            composition['C'], composition['Si'], composition['Mn'],
            composition['Cu'], composition['Mg']
        ]),
        'Carbon_Equivalent': (composition['C'] + 
                             composition['Si']/4 + 
                             composition['P']/2)
    })
    
    return pd.DataFrame([features])
```

## ğŸ”Œ API Endpoints Design

### 1. Health Check Endpoint

```python
@app.get("/health")
async def health_check():
    """System health and model status"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "models_loaded": len(models),
        "available_grades": list(TARGET_SPECS.keys()),
        "system_info": {
            "python_version": platform.python_version(),
            "fastapi_version": fastapi.__version__,
            "gpu_available": torch.cuda.is_available() if torch else False
        }
    }
```

### 2. Core Prediction Endpoint

```python
@app.post("/predict-element-config", response_model=PredictionResponse)
async def predict_element_config(request: PredictionRequest):
    """Main prediction endpoint with comprehensive response"""
    
    try:
        # Model loading and selection
        model = select_model(request.alloy_grade)
        
        # Feature preparation
        features = prepare_features(request)
        
        # Ensemble prediction
        predictions = model.predict(features)
        
        # Optimization and cost analysis
        optimization = calculate_optimization(
            current=request.current_composition,
            predicted=predictions,
            target=TARGET_SPECS[request.alloy_grade]
        )
        
        # Response formatting
        return format_prediction_response(
            request, predictions, optimization
        )
        
    except Exception as e:
        logger.error(f"Prediction error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
```

### 3. Batch Prediction Endpoint

```python
@app.post("/predict-batch")
async def predict_batch(requests: List[PredictionRequest]):
    """Batch processing for multiple predictions"""
    
    results = []
    for request in requests:
        try:
            result = await predict_element_config(request)
            results.append(result)
        except Exception as e:
            results.append({
                "success": False,
                "error": str(e),
                "alloy_grade": request.alloy_grade
            })
    
    return {
        "batch_size": len(requests),
        "successful_predictions": sum(1 for r in results if r.get("success")),
        "results": results
    }
```

## ğŸ” Error Handling & Logging

### Exception Handling Strategy

```python
from fastapi import HTTPException
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('alloymind.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Custom exception handlers
@app.exception_handler(ValueError)
async def value_error_handler(request, exc):
    logger.error(f"Value error: {str(exc)}")
    return JSONResponse(
        status_code=400,
        content={"detail": f"Invalid input: {str(exc)}"}
    )

@app.exception_handler(FileNotFoundError)
async def model_not_found_handler(request, exc):
    logger.error(f"Model file not found: {str(exc)}")
    return JSONResponse(
        status_code=503,
        content={"detail": "Model not available. Please contact support."}
    )
```

## ğŸ“ˆ Performance Optimizations

### 1. Model Caching
- Pre-load models into memory on startup
- Lazy loading for unused models
- Memory-efficient model storage

### 2. Async Processing
- FastAPI async/await for I/O operations
- Non-blocking prediction pipeline
- Concurrent batch processing

### 3. Response Optimization
- Automatic response compression (gzip)
- Structured JSON responses
- Minimal response payload size

### 4. GPU Utilization
- LightGBM GPU acceleration
- CUDA-optimized training
- Efficient memory management

## ğŸš€ Deployment Architecture

### Production Deployment

```yaml
# docker-compose.yml
version: '3.8'
services:
  alloymind-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - WORKERS=4
      - GPU_ENABLED=true
    volumes:
      - ./models:/app/models
    restart: always
    
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - alloymind-api
```

### Scalability Considerations

1. **Horizontal Scaling**: Multiple API instances behind load balancer
2. **Model Versioning**: A/B testing framework for model updates
3. **Caching Layer**: Redis for frequently accessed predictions
4. **Monitoring**: Prometheus + Grafana for metrics
5. **Security**: API authentication and rate limiting

---

This architecture provides a robust, scalable, and high-performance ML serving system optimized for industrial alloy manufacturing applications.
